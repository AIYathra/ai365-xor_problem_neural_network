ğŸ§  ai365-xor_problem_neural_network
ğŸ” Overview
This repository explores the classic XOR problem â€” a foundational challenge in neural network history â€” and demonstrates how a simple multi-layer perceptron (MLP) can solve it using non-linear activation functions.

ğŸ¯ Whatâ€™s Inside
A minimal Keras/TensorFlow model that learns the XOR truth table.

Visualizations of input/output mappings and decision boundaries.

Deployment-ready code for running the trained model on a microcontroller using TensorFlow Lite Micro (TinyML).

Commentary on why XOR is not linearly separable and how hidden layers enable learning.

ğŸš€ Goals
Understand the limitations of single-layer perceptrons.

Implement a working neural network that solves XOR.

Prepare the model for edge deployment on resource-constrained devices.

ğŸ“¦ Files
xor_model.ipynb: Training and evaluation notebook.

model.tflite: Quantized model for microcontroller inference.

README.md: Explanation of the problem, architecture, and results.

visuals/: Diagrams and plots showing how the network separates XOR inputs.

ğŸ“š Learning Outcome
Solving XOR is more than a coding exercise â€” itâ€™s a gateway to understanding non-linearity, activation functions, and the power of hidden layers. This repo sets the stage for deeper neural network experiments in AI365.