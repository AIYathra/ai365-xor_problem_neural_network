# ğŸ§  XOR Neural Network â€” Solving the Classic Nonâ€‘Linear Problem

A minimal, handsâ€‘on implementation of the XOR problem using a simple neural network built with TensorFlow/Keras. This project demonstrates how nonâ€‘linear activation functions and a hidden layer enable a model to learn a function that a singleâ€‘layer perceptron cannot solve.


## ğŸš€ Project Overview

The XOR (exclusive OR) problem is historically important in the evolution of neural networks. It represents the simplest example of a **nonâ€‘linearly separable** function â€” meaning it cannot be solved by a linear classifier.

This repository walks through:

- Building the XOR dataset  
- Designing a small neural network with a hidden layer  
- Training the model to learn XOR  
- Testing predictions  
- Converting the trained model into TensorFlow Lite format  

This project is intentionally simple and ideal for beginners who want to understand *why* neural networks need nonâ€‘linearity and hidden layers.


## ğŸ“‚ Repository Structure

ai365-xor_problem_neural_network/
```text
â”œâ”€â”€ Xor.ipynb              # Jupyter Notebook with full implementation
â”œâ”€â”€ converted_model.tflite # Exported TensorFlow Lite model
â””â”€â”€ README.md              # Project documentation
```


## ğŸ§© The XOR Dataset

The XOR truth table:

| Input (x1, x2) | Output |
|----------------|--------|
| (0, 0)         |   0    |
| (0, 1)         |   1    |
| (1, 0)         |   1    |
| (1, 1)         |   0    |

This dataset cannot be separated by a straight line, which is why a hidden layer is required.


## ğŸ—ï¸ Model Architecture

The neural network used in this project:

- **Input layer:** 2 features  
- **Hidden layer:** 2 neurons, `tanh` activation  
- **Output layer:** 1 neuron, `sigmoid` activation  
- **Loss:** Binary crossâ€‘entropy  
- **Optimizer:** Adam  

This minimal architecture is sufficient to learn the XOR mapping.


## ğŸƒ Training

The model is trained for 10,000 epochs with batch size 1.  
After training, the network correctly predicts the XOR outputs.

Example output:
[[0.01]
[0.98]
[0.97]
[0.02]]


(Rounded â†’ `[[0], [1], [1], [0]]`)


## ğŸ“¦ TensorFlow Lite Conversion

The trained Keras model is converted into a `.tflite` file using:

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
```
This enables deployment on microcontrollers or edge devices.


## ğŸ¯ Learning Outcome
By completing this project, learn:
- Why XOR is a foundational problem in neural network history
- How hidden layers and nonâ€‘linear activations enable complex decision boundaries
- How to build, train, and test a neural network in TensorFlow/Keras
- How to export a model to TensorFlow Lite
This is a perfect stepping stone toward deeper neural network concepts and embedded AI.


## ğŸ“š Learning Resources
New to neural networks? Check out our detailed tutorial!
ğŸ“š **[Line-by-Line Tutorial](xor_tutorial_line_by_line.md)** - Perfect for beginners! Every line of code explained in simple terms.


## ğŸ“˜ Educational Purpose
This repository is created purely for educational and learning purposes. It is designed to help beginners understand the fundamentals of neural networks through the classic XOR problem.